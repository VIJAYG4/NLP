{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re,collections\n",
    "from math import log\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('True.csv')\n",
    "df_real['RealNews?'] = True\n",
    "df_fake = pd.read_csv('Fake.csv')\n",
    "df_fake['RealNews?'] = False\n",
    "df = df_real.append(df_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subject', 'date', 'RealNews?'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['document']=df[['title','text']].agg(' '.join,axis=1).apply(lambda x:x.lower())\n",
    "df['text']=df['text'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer produces a feature matrix of token counts for text. \n",
    "tf_vectorizer = CountVectorizer(stop_words='english')\n",
    "x = tf_vectorizer.fit_transform(df['text'])\n",
    "#fit the lda model with 10 topics\n",
    "lda = LatentDirichletAllocation(n_components=10,random_state=0)\n",
    "lda.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the top_n words for each topic\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: trump said republican house president senate republicans tax washington reuters white obama congress senator new democrats donald democratic year plan\n",
      "Topic #1: police said year people city old told killed officers man family years arrested according death attack shooting group black officer\n",
      "Topic #2: said state million 000 election government year money billion company new according percent companies reuters federal city public states vote\n",
      "Topic #3: court said law trump president states obama federal order supreme immigration justice judge administration department united case legal ban climate\n",
      "Topic #4: trump said russia russian president fbi clinton intelligence investigation campaign house news election information committee comey security washington director department\n",
      "Topic #5: clinton party hillary election percent said democratic voters sanders new campaign vote poll political presidential candidate support democrats polls year\n",
      "Topic #6: trump people donald president just like twitter said obama white don know image time going news featured right com think\n",
      "Topic #7: people women gun america like state american children new students law muslim school rights right group world just religious public\n",
      "Topic #8: said government minister eu european reuters president israel britain united prime mexico trade states turkey union talks border parliament deal\n",
      "Topic #9: said united north military china state reuters korea states iran president nuclear syria security trump government foreign war al told\n"
     ]
    }
   ],
   "source": [
    "#print the topics of lda model\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 121690)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121690"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most of the topics are related to politics. Topics such as fbi investigation, law on climate change, tax plan are found by the lda model. Its a good representation of real-world topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample 5 real news and 5 fake news\n",
    "df_sampled = df[df['RealNews?']==True].sample(n=5).append(df[df['RealNews?']==False].sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>RealNews?</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20627</td>\n",
       "      <td>Trump visit to Britain still unfixed nine mont...</td>\n",
       "      <td>london (reuters) - nine months after prime min...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 8, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>trump visit to britain still unfixed nine mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8423</td>\n",
       "      <td>Clinton leads Trump by eight points: Reuters/I...</td>\n",
       "      <td>new york (reuters) - democratic presidential c...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>August 19, 2016</td>\n",
       "      <td>True</td>\n",
       "      <td>clinton leads trump by eight points: reuters/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18904</td>\n",
       "      <td>Iraq sends delegation to Iran 'to coordinate m...</td>\n",
       "      <td>baghdad (reuters) - a top ranking delegation f...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>iraq sends delegation to iran 'to coordinate m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19052</td>\n",
       "      <td>China busts underground bank in Guangzhou: Chi...</td>\n",
       "      <td>shanghai (reuters) - chinese police have broke...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 26, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>china busts underground bank in guangzhou: chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15771</td>\n",
       "      <td>Myanmar sees 'bad consequences' if U.S. impose...</td>\n",
       "      <td>yangon (reuters) - proposed u.s. sanctions tar...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 3, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>myanmar sees 'bad consequences' if u.s. impose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15507</td>\n",
       "      <td>https://100percentfedup.com/video-hillary-aske...</td>\n",
       "      <td>https://100percentfedup.com/video-hillary-aske...</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://100percentfedup.com/video-hillary-aske...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://100percentfedup.com/video-hillary-aske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22173</td>\n",
       "      <td>BIGGER THAN SNOWDEN: Wikileaks ‘Vault 7’ Class...</td>\n",
       "      <td>he who controls the spice controls the univer...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>March 13, 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>bigger than snowden: wikileaks ‘vault 7’ class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19886</td>\n",
       "      <td>WHOA! DEMOCRATIC Strategist Gives Crooked Hill...</td>\n",
       "      <td>the most unpopular, deplorable woman in americ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Oct 2, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>whoa! democratic strategist gives crooked hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5524</td>\n",
       "      <td>Sean Hannity Just Made A Bizarre Implication ...</td>\n",
       "      <td>sean hannity made a bizarre implication during...</td>\n",
       "      <td>News</td>\n",
       "      <td>July 10, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>sean hannity just made a bizarre implication ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20061</td>\n",
       "      <td>WHY TRUMP SUPPORTERS ARE LAUGHING After WikiLe...</td>\n",
       "      <td>fans of #crookedhillary are not going to like ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Aug 28, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>why trump supporters are laughing after wikile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "20627  Trump visit to Britain still unfixed nine mont...   \n",
       "8423   Clinton leads Trump by eight points: Reuters/I...   \n",
       "18904  Iraq sends delegation to Iran 'to coordinate m...   \n",
       "19052  China busts underground bank in Guangzhou: Chi...   \n",
       "15771  Myanmar sees 'bad consequences' if U.S. impose...   \n",
       "15507  https://100percentfedup.com/video-hillary-aske...   \n",
       "22173  BIGGER THAN SNOWDEN: Wikileaks ‘Vault 7’ Class...   \n",
       "19886  WHOA! DEMOCRATIC Strategist Gives Crooked Hill...   \n",
       "5524    Sean Hannity Just Made A Bizarre Implication ...   \n",
       "20061  WHY TRUMP SUPPORTERS ARE LAUGHING After WikiLe...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "20627  london (reuters) - nine months after prime min...     worldnews   \n",
       "8423   new york (reuters) - democratic presidential c...  politicsNews   \n",
       "18904  baghdad (reuters) - a top ranking delegation f...     worldnews   \n",
       "19052  shanghai (reuters) - chinese police have broke...     worldnews   \n",
       "15771  yangon (reuters) - proposed u.s. sanctions tar...     worldnews   \n",
       "15507  https://100percentfedup.com/video-hillary-aske...      politics   \n",
       "22173   he who controls the spice controls the univer...       US_News   \n",
       "19886  the most unpopular, deplorable woman in americ...     left-news   \n",
       "5524   sean hannity made a bizarre implication during...          News   \n",
       "20061  fans of #crookedhillary are not going to like ...     left-news   \n",
       "\n",
       "                                                    date  RealNews?  \\\n",
       "20627                                 September 8, 2017        True   \n",
       "8423                                    August 19, 2016        True   \n",
       "18904                                September 27, 2017        True   \n",
       "19052                                September 26, 2017        True   \n",
       "15771                                  November 3, 2017        True   \n",
       "15507  https://100percentfedup.com/video-hillary-aske...      False   \n",
       "22173                                     March 13, 2017      False   \n",
       "19886                                        Oct 2, 2016      False   \n",
       "5524                                       July 10, 2016      False   \n",
       "20061                                       Aug 28, 2016      False   \n",
       "\n",
       "                                                document  \n",
       "20627  trump visit to britain still unfixed nine mont...  \n",
       "8423   clinton leads trump by eight points: reuters/i...  \n",
       "18904  iraq sends delegation to iran 'to coordinate m...  \n",
       "19052  china busts underground bank in guangzhou: chi...  \n",
       "15771  myanmar sees 'bad consequences' if u.s. impose...  \n",
       "15507  https://100percentfedup.com/video-hillary-aske...  \n",
       "22173  bigger than snowden: wikileaks ‘vault 7’ class...  \n",
       "19886  whoa! democratic strategist gives crooked hill...  \n",
       "5524    sean hannity just made a bizarre implication ...  \n",
       "20061  why trump supporters are laughing after wikile...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 belongs to topic 8\n",
      "document 2 belongs to topic 5\n",
      "document 3 belongs to topic 9\n",
      "document 4 belongs to topic 9\n",
      "document 5 belongs to topic 9\n",
      "document 6 belongs to topic 6\n",
      "document 7 belongs to topic 4\n",
      "document 8 belongs to topic 5\n",
      "document 9 belongs to topic 6\n",
      "document 10 belongs to topic 4\n"
     ]
    }
   ],
   "source": [
    "#get topics for each document\n",
    "x_sampled = tf_vectorizer.transform(df_sampled['text'])\n",
    "topics_prob = lda.transform(x_sampled)\n",
    "#print(topics_prob.shape)\n",
    "docs_topics = np.argmax(topics_prob,axis=1)\n",
    "for i in range(len(docs_topics)):\n",
    "    print(\"document {} belongs to topic {}\".format(i+1, docs_topics[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic 9(US and North Korea nuclear war)is prevalent in real news articles. topics 4 and 6 are prevalent in fake news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35918, 6) (8980, 6)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "print(df_train.shape,df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer produces a feature matrix of token counts for text. \n",
    "tf_vectorizer = CountVectorizer(stop_words='english')\n",
    "x_train = tf_vectorizer.fit_transform(df_train['text'])\n",
    "#fit the lda model with 10 topics\n",
    "lda = LatentDirichletAllocation(n_components=10,random_state=0)\n",
    "lda.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (35918, 10)\n",
      "y_train shape: (35918,)\n",
      "x_test shape: (8980, 10)\n",
      "y_test shape: (8980,)\n"
     ]
    }
   ],
   "source": [
    "#get lda vectors for train and test docs\n",
    "x_train = lda.transform(x_train)\n",
    "x_test = tf_vectorizer.transform(df_test['text'])\n",
    "x_test = lda.transform(x_test)\n",
    "y_train,y_test= df_train['RealNews?'],df_test['RealNews?']\n",
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_test shape:\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vijay/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model performance on lda vectors:\n",
      "Accuracy score is 0.884075723830735\n",
      "Precision score is 0.8751450452541193\n",
      "Recall score is 0.8823116518483856\n",
      "F1 score is 0.8787137364557847\n",
      "Area Under the Curve(ROC curve) is 0.9532763508825242\n",
      "true negative 4168\n",
      "false positive 538\n",
      "false negative 503\n",
      "true positive 3771\n",
      "specificity is 0.8856778580535487\n"
     ]
    }
   ],
   "source": [
    "#train the logistic regression clf\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred = lr.predict(x_test)\n",
    "y_prob = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "#model evaluation\n",
    "print(\"Logistic regression model performance on lda vectors:\")\n",
    "print(\"Accuracy score is {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Precision score is {}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score is {}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1 score is {}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "print(\"Area Under the Curve(ROC curve) is {}\".format(roc_auc_score(y_test,y_prob)))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "\n",
    "print(\"true negative\", tn)\n",
    "print(\"false positive\", fp)\n",
    "print(\"false negative\", fn)\n",
    "print(\"true positive\", tp)\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"specificity is {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful topics ranked from most useful to least useful [[2 3 9 1 4 0 8 6 7 5]]\n",
      "scores for corresponding topics [[ 1.38789583  2.53022141  5.22121393  4.06925796  1.45932434 -7.8030476\n",
      "  -2.16746468 -6.43829936 -1.63321257  3.21623314]]\n"
     ]
    }
   ],
   "source": [
    "#get the most useful topics for classification\n",
    "topics_importance_score = lr.coef_\n",
    "useful_topics = np.flip(np.argsort(topics_importance_score))\n",
    "print(\"useful topics ranked from most useful to least useful\", useful_topics)\n",
    "print(\"scores for corresponding topics\",topics_importance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top 3 most useful topics in classification of real or fake news is topic 2, topic 3 and topic 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only real news\n",
    "df_real = df[df['RealNews?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of real news lda vectors is (21417, 10)\n"
     ]
    }
   ],
   "source": [
    "#get the lda vectors for real news docs\n",
    "# CountVectorizer produces a feature matrix of token counts for text. \n",
    "tf_vectorizer = CountVectorizer(stop_words='english')\n",
    "x = tf_vectorizer.fit_transform(df_real['text'])\n",
    "#fit the lda model with 10 topics\n",
    "lda = LatentDirichletAllocation(n_components=10,random_state=0)\n",
    "lda.fit(x)\n",
    "x = lda.transform(x)\n",
    "print(\"shape of real news lda vectors is\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster the docs using k-means\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 4, 5, 7, 8]), array([ 919, 1227, 1345, 1349, 1351]), array([ 15,  34,  66, 175, 178]), array([ 2,  3,  6,  9, 10]), array([43, 47, 61, 64, 65]), array([348, 363, 504, 571, 765]), array([ 33, 101, 105, 121, 128]), array([ 1, 18, 20, 21, 22]), array([ 24, 452, 456, 461, 485]), array([447, 448, 549, 552, 572])]\n"
     ]
    }
   ],
   "source": [
    "#get 5 documents from each cluster\n",
    "y_pred = kmeans.labels_\n",
    "n_clusters=10\n",
    "#stores docs index for each cluster \n",
    "docs_index_by_clusters=[]\n",
    "for i in range(n_clusters):\n",
    "    #get all docs index for each cluster\n",
    "    docs_index = np.where(y_pred==i)[0]\n",
    "    #consider only 5 docs for each cluster\n",
    "    docs_index = docs_index[:5]\n",
    "    docs_index_by_clusters.append(docs_index)\n",
    "print(docs_index_by_clusters)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document titles belonging to cluster 0\n",
      "----------------------------------------\n",
      "As U.S. budget fight looms, Republicans flip their fiscal script\n",
      "Trump wants Postal Service to charge 'much more' for Amazon shipments\n",
      "White House, Congress prepare for talks on spending, immigration\n",
      "Factbox: Trump on Twitter (Dec 29) - Approval rating, Amazon\n",
      "Trump on Twitter (Dec 28) - Global Warming\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 1\n",
      "----------------------------------------\n",
      "North Korean defector pushes diplomatic solution in U.S. Congress\n",
      "North Korea not ready to meet with South Korea in Russia: agencies\n",
      "Turkey urges U.S. to review visa suspension as lira, stocks tumble\n",
      "Turkey's Erdogan says U.S. decision to suspend visa services 'upsetting'\n",
      "Turkey summons U.S. consulate worker for questioning: Anadolu\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 2\n",
      "----------------------------------------\n",
      "Virginia officials postpone lottery drawing to decide tied statehouse election\n",
      "As Republicans aim to ride economy to election victory, a warning from voters in key district\n",
      "In Georgia, battle of the 'Staceys' tests Democrats' future\n",
      "After Alabama upset, Democrats see new prospects in U.S. South\n",
      "Control of Virginia state House at stake as recounts begin\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 3\n",
      "----------------------------------------\n",
      "Senior U.S. Republican senator: 'Let Mr. Mueller do his job'\n",
      "FBI Russia probe helped by Australian diplomat tip-off: NYT\n",
      "Trump says Russia probe will be fair, but timeline unclear: NYT\n",
      "Alabama official to certify Senator-elect Jones today despite challenge: CNN\n",
      "Jones certified U.S. Senate winner despite Moore challenge\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 4\n",
      "----------------------------------------\n",
      "U.S. House approves $81 billion for disaster aid\n",
      "U.S. launches effort to reduce reliance on imports or critical minerals\n",
      "White House says tax bill will not hurt Puerto Rico\n",
      "Fight over Alaska Arctic drilling has just begun, opponents vow\n",
      "Senator Cornyn trying to get Big Corn behind U.S. biofuels reform\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 5\n",
      "----------------------------------------\n",
      "U.S. defense chief urges Pakistan to redouble efforts against militants\n",
      "U.S. embassy to Russia to resume some visa services after diplomatic row\n",
      "Russian envoy to U.S. to inspect San Francisco consulate: RIA\n",
      "Putin, Trump to discuss North Korea on Tuesday: IFX cites Kremlin aide\n",
      "White House condemns missile attacks on Saudi by Yemen's Houthis\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 6\n",
      "----------------------------------------\n",
      "Callista Gingrich becomes Trump's envoy to pope as differences mount\n",
      "Trump strategy document says Russia meddles in domestic affairs worldwide\n",
      "Trump: U.S. has 'no choice' but to deal with North Korea arms challenge\n",
      "Trump to say in security speech that China is competitor: officials\n",
      "Trump officials brief Hill staff on Saudi reactors, enrichment a worry\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 7\n",
      "----------------------------------------\n",
      "U.S. military to accept transgender recruits on Monday: Pentagon\n",
      "U.S. appeals court rejects challenge to Trump voter fraud panel\n",
      "Federal judge partially lifts Trump's latest refugee restrictions\n",
      "Exclusive: U.S. memo weakens guidelines for protecting immigrant children in court\n",
      "Trump travel ban should not apply to people with strong U.S. ties: court\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 8\n",
      "----------------------------------------\n",
      "Failed vote to oust president shakes up Peru's politics\n",
      "Britain's U.S. ambassador discussed Trump retweets with senior White House staff: source\n",
      "British minister hopes condemnation of Trump tweet has impact\n",
      "Trump fires back at Britain's May: 'Don't focus on me'\n",
      "Factbox: Who are Britain First, whose leader's posts Trump re-tweeted?\n",
      "-------------------------------------\n",
      "document titles belonging to cluster 9\n",
      "----------------------------------------\n",
      "Trump angers UK with truculent tweet to May after sharing far-right videos\n",
      "U.N. rights boss condemns \"spreading hatred through tweets\"\n",
      "U.S. calls Myanmar moves against Rohingya 'ethnic cleansing'\n",
      "U.S. hopes to pressure Myanmar to permit Rohingya repatriation\n",
      "U.S. Congress members decry 'ethnic cleansing' in Myanmar; Suu Kyi doubts allegations\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print the titles of documents belonging to each cluster to find similarity\n",
    "for i in range(len(docs_index_by_clusters)):\n",
    "    print(\"document titles belonging to cluster\",i)\n",
    "    print(\"----------------------------------------\")\n",
    "    docs_indexes = docs_index_by_clusters[i]\n",
    "    for j in docs_indexes:\n",
    "        print(df_real.iloc[j]['title'])\n",
    "    print(\"-------------------------------------\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is some similarity between documents in each cluster. For example, docs in cluster 9 are about US opposition on Myanmar's ethnic cleansing, cluster 2 is about elections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
